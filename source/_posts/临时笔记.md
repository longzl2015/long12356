## yarn日志



yarn.log.server.url

Yarn.log-aggregat

Yarn.nodemanager.log-dirs



hadoop 用户 系统

```
UserGroupInformation.getCurrentUser().getShortUserName()


// spark 用户设置
System.getenv("SPARK_USER")


//hadoop 
HADOOP_PROXY_USER


//System.getenv
//System.getProperty

 loginUserFromSubject
 createProxyUser(proxyUser, realUser); 
```



hadoop 用户代理机制



hadoop 日志聚合 提交用户的文件目录下 即 服务器的当前用户



## 建模平台 ETL 思路

需求：

- 读取mysql和oracle数据库信息
- 将信息转为parquet文件
- 是否需要支持定时增量读取，通过时间分区实现增量操作。
- 需要支持分区功能，按时间分区？
- 准实时同步，由于是离线属性的，不需要实时同步
- 如何注册到 mgr 中



增量读取：获取特定小时、天或月的数据，分区存入hadoop，分区路径格式 key=value

定时执行ETL功能、使用



1. 支持分区后，parquet 文件大小如何确认？
2. 递归判断（识别parquet字符串结尾的文件）
3. 预览时判断是否为parquet文件，有必要吗？直接读取，如果出错直接异常？





### 1、使用sqoop

优点： 支持MapReduce，速度较普通java程序快

缺点： 不支持 = 路径 仅支持` [a-zA-Z0-9_]+ `路径

使用方法：修改源码去掉路径校验

### 2、datax

优点：支持多种数据相互转换，sqoop同样支持。

缺点：暂无parquet格式支持

### 3、自己写spark程序

可以先考虑 mysql 、oracle类型

实现思路：



### 4、hive和sqoop结合

不考虑



京东 15000

余额宝 5000

微贷 15000

广发 12100

招商11800

基金4000



## 啄木鸟设计 

### 1. 字段信息获取接口：

EDIP 导入时 flg和Excel解析

数据列表修改页面的 脱敏信息修改

- flg等格式文件获取
- parquet文件中获取，从dwtable表中获取使用
- dwtable的sensitive中获取

```
JAXBUtil.marshalPMML(pmml, new StreamResult(System.out))
  ComponentUtils.deleteExistedPath(app.getOutput)
FileSystem.newInstance(new Configuration()).copyFromLocalFile(new Path(System.getProperty("spark.yarn.app.container.log.dir")+"/stdout"), new Path(app.getOutput))
```





### DAG 设计



**TaskRunner**

- taskId
- threadName
- taskName
- killed
- threaId
- Finished



DELETE FROM QRTZ_SIMPLE_TRIGGERS WHERE TRIGGER_NAME = '1s_daemon';
DELETE FROM QRTZ_TRIGGERS WHERE TRIGGER_NAME = '1s_daemon';
DELETE FROM QRTZ_JOB_DETAILS WHERE JOB_NAME = '1s_daemon';



```
-- auto-generated definition
create table P_ORG
(
	ORG_ID NUMBER(18) not null
		primary key,
	ORG_NAME VARCHAR2(64) not null,
	STATUS NUMBER(5) not null,
	PARENT_ID NUMBER(18) not null,
	CREATE_TIME TIMESTAMP(6) not null,
	CREATE_USER_ID NUMBER(18) not null,
	UPDATE_TIME TIMESTAMP(6),
	UPDATE_USER_ID NUMBER(18) not null
)
/

comment on column P_ORG.ORG_NAME is 'Organization name'
/

comment on column P_ORG.STATUS is 'Organization status'
/

comment on column P_ORG.PARENT_ID is 'Superior organization Id'
/



-- auto-generated definition
create table P_USERS
(
	USER_ID NUMBER(18) not null
		primary key,
	ORGANIZATION_ID NUMBER(18) not null,
	LOGIN_NAME VARCHAR2(64) not null
		constraint P_USERS_C1
			unique,
	LOGIN_PASSWD VARCHAR2(64) not null,
	NAME VARCHAR2(64) not null,
	SEX CHAR(2),
	JOB VARCHAR2(64),
	MOBILE VARCHAR2(20),
	EMAIL VARCHAR2(64),
	STATUS NUMBER(5) not null,
	BANK_STATUS NUMBER(5) not null,
	CREATE_TIME TIMESTAMP(6) not null,
	CREATE_USER_ID NUMBER(18) not null,
	UPDATE_TIME TIMESTAMP(6),
	UPDATE_USER_ID NUMBER(18) not null
)
/

comment on column P_USERS.NAME is 'Real name of the user'
/

comment on column P_USERS.JOB is 'User positions'
/

comment on column P_USERS.STATUS is 'mgr platform status'
/

comment on column P_USERS.BANK_STATUS is 'euip status from bank'
/





```

